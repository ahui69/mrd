# üß† JAK SYSTEM WCZYTUJE I U≈ªYWA WIEDZY

## üìö GDZIE JEST WIEDZA?

### 1. BAZA SQLite
```
/workspace/data/monolit.db
Tabela: ltm (Long-Term Memory)

Struktura:
- id          (hash tekstu)
- text        (tre≈õƒá faktu)
- tags        (kategorie, np. "moda,vinted,pricing")
- source      (≈∫r√≥d≈Ço, np. "Fashion Encyclopedia")
- conf        (pewno≈õƒá, 0.0-1.0)
- created_at  (timestamp)
```

**Aktualna zawarto≈õƒá:**
- ~2932 fakt√≥w w bazie (po ostatnim wgraniu)
- 8 kategorii: moda, Vinted, social, aukcje, psychologia, pisanie, kod, geografia

---

## üîÑ JAK SYSTEM WCZYTUJE WIEDZƒò?

### SPOS√ìB 1: Automatycznie przy starcie serwera ‚ùå

**NIE - fakty NIE sƒÖ ≈Çadowane do pamiƒôci przy starcie!**

Baza SQLite jest odczytywana **na ≈ºƒÖdanie** gdy:
- U≈ºytkownik zadaje pytanie
- System wykonuje `ltm_search()`

### SPOS√ìB 2: Podczas chat'a (on-demand) ‚úÖ

**TAK - to g≈Ç√≥wny spos√≥b!**

```python
# W assistant_endpoint.py (uproszczony flow):

1. User: "Co wiesz o Chanel?"

2. System wywo≈Çuje: ltm_search(query="Chanel", limit=5)
   
3. SQLite SELECT:
   SELECT * FROM ltm 
   WHERE tags LIKE '%chanel%' OR text LIKE '%Chanel%'
   ORDER BY relevance
   LIMIT 5

4. Zwraca np.:
   - "Coco Chanel revolutionized women's fashion..."
   - "Chanel No. 5 perfume remains timeless..."
   - "Chanel's little black dress..."

5. Te fakty sƒÖ dodawane do promptu LLM jako KONTEKST

6. LLM generuje odpowied≈∫ U≈ªYWAJƒÑC tych fakt√≥w
```

---

## üîç DOK≈ÅADNY FLOW (krok po kroku):

### A. U≈ºytkownik wysy≈Ça wiadomo≈õƒá

```javascript
// frontend.html
sendMessage() {
  fetch('/api/chat/assistant', {
    body: JSON.stringify({
      messages: [...],
      use_memory: true  // ‚Üê W≈ÅƒÑCZ PAMIƒòƒÜ!
    })
  })
}
```

### B. Backend (assistant_endpoint.py)

```python
@router.post("/chat/assistant")
async def chat_assistant(req: ChatRequest):
    
    # 1. WyciƒÖgnij ostatniƒÖ wiadomo≈õƒá u≈ºytkownika
    user_msg = req.messages[-1].content
    
    # 2. SZUKAJ W LTM (je≈õli use_memory=true)
    if req.use_memory:
        ltm_facts = M.ltm_search_hybrid(
            query=user_msg,
            topk=5  # We≈∫ top 5 fakt√≥w
        )
        # ltm_facts = [
        #   {"text": "Chanel...", "score": 0.85},
        #   {"text": "Haute couture...", "score": 0.72},
        #   ...
        # ]
    
    # 3. Dodaj fakty do SYSTEM PROMPT
    system_prompt = f"""
    Jeste≈õ Mordzix. U≈ºywaj fakt√≥w z bazy:
    
    FAKTY:
    {ltm_facts[0]['text']}
    {ltm_facts[1]['text']}
    ...
    
    USER: {user_msg}
    """
    
    # 4. Wy≈õlij do LLM
    response = llm_call(system_prompt)
    
    # 5. Zwr√≥ƒá odpowied≈∫
    return {"answer": response}
```

### C. SQLite (monolit.py)

```python
def ltm_search_hybrid(query, topk=5):
    """Hybrid search: BM25 + TF-IDF"""
    
    # 1. Tokenizuj query
    tokens = query.lower().split()
    
    # 2. Szukaj w bazie
    conn = sqlite3.connect('data/monolit.db')
    
    # Metoda 1: Szukaj po tagach
    for token in tokens:
        results = conn.execute("""
            SELECT * FROM ltm 
            WHERE tags LIKE ?
        """, (f'%{token}%',))
    
    # Metoda 2: Szukaj po tre≈õci
    results += conn.execute("""
        SELECT * FROM ltm 
        WHERE text LIKE ?
    """, (f'%{query}%',))
    
    # 3. Scoruj wyniki (TF-IDF)
    scored = []
    for row in results:
        score = calculate_tfidf(row['text'], query)
        scored.append({
            'text': row['text'],
            'score': score,
            'tags': row['tags'],
            'source': row['source']
        })
    
    # 4. Sortuj i zwr√≥ƒá top K
    scored.sort(key=lambda x: x['score'], reverse=True)
    return scored[:topk]
```

---

## üì• JAK DODAƒÜ NOWE FAKTY?

### SPOS√ìB 1: API Endpoint

```bash
curl -X POST http://localhost:8080/api/ltm/add \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Vue 3 uses Composition API for better TypeScript support",
    "tags": ["kod", "vue", "javascript"],
    "source": "Vue 3 Docs",
    "conf": 0.9
  }'
```

### SPOS√ìB 2: Auto-uczenie (frontend)

```
1. Sidebar ‚Üí "üéì Auto-uczenie"
2. Wpisz has≈Ço: "Vue 3"
3. Kliknij "üîç Naucz siƒô"

‚Üí System:
  - Szuka w DuckDuckGo
  - Pobiera top 5 wynik√≥w
  - Zapisuje top 3 do LTM
```

### SPOS√ìB 3: Python script (bulk)

```python
import sqlite3, hashlib, time

facts = [
    {"text": "...", "tags": ["moda"], "source": "..."},
    # ... wiƒôcej fakt√≥w
]

conn = sqlite3.connect('data/monolit.db')
for fact in facts:
    fact_id = hashlib.sha256(fact['text'].encode()).hexdigest()[:16]
    tags_str = ','.join(fact['tags'])
    
    conn.execute("""
        INSERT OR IGNORE INTO ltm 
        (id, text, tags, source, conf, created_at)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (fact_id, fact['text'], tags_str, 
          fact['source'], 0.8, int(time.time())))

conn.commit()
```

### SPOS√ìB 4: Z pliku JSON

```bash
# Masz facts_complete.json (5200+ fakt√≥w)
python3 << 'EOF'
import sqlite3, json, hashlib, time

with open('facts_complete.json') as f:
    facts = json.load(f)

conn = sqlite3.connect('data/monolit.db')
cur = conn.cursor()

for fact in facts:
    fact_id = hashlib.sha256(fact['text'].encode()).hexdigest()[:16]
    tags_str = ','.join(fact['tags']) if isinstance(fact['tags'], list) else fact['tags']
    
    cur.execute('''
        INSERT OR IGNORE INTO ltm 
        VALUES (?,?,?,?,?,?)
    ''', (fact_id, fact['text'], tags_str, 
          fact.get('source',''), fact.get('conf',0.75), 
          int(time.time())))

conn.commit()
print(f'‚úÖ Wgrano {len(facts)} fakt√≥w')
EOF
```

---

## ‚úÖ CZY WIEDZA DZIA≈ÅA?

### Test 1: Sprawd≈∫ bazƒô

```bash
sqlite3 data/monolit.db "SELECT COUNT(*) FROM ltm;"
# Powinno pokazaƒá ~2932+

sqlite3 data/monolit.db "SELECT * FROM ltm LIMIT 3;"
# Powinno pokazaƒá przyk≈Çadowe fakty
```

### Test 2: Test search

```bash
curl -H "Authorization: Bearer $TOKEN" \
  "http://localhost:8080/api/ltm/search?q=chanel&limit=3"

# Powinno zwr√≥ciƒá fakty o Chanel
```

### Test 3: Test w chacie

```
User: "Co wiesz o Coco Chanel?"

System powinien:
‚úÖ Znale≈∫ƒá fakty o Chanel w LTM
‚úÖ U≈ºyƒá ich w odpowiedzi
‚úÖ Podaƒá konkretne detale (np. "Chanel No. 5", "little black dress")
```

---

## üî• KLUCZOWE PUNKTY:

1. **Wiedza = SQLite database** (`data/monolit.db`)
2. **≈Åadowanie = On-demand** (nie przy starcie, ale przy ka≈ºdym pytaniu)
3. **Search = Hybrid** (tags + full-text + TF-IDF scoring)
4. **Dodawanie = 4 sposoby** (API, auto-learn, script, bulk JSON)
5. **U≈ºywanie = Automatyczne** (je≈õli `use_memory: true` w request)

---

## üìä OBECNY STAN:

```
Fakty w bazie:     ~2932 (po ostatnim wgraniu)
Kategorii:         8 (moda, Vinted, social, etc.)
Format:            SQLite (szybki, offline)
Search:            Hybrid (BM25 + TF-IDF)
Auto-load:         NIE (on-demand)
Performance:       < 100ms na query
```

---

## ‚ö†Ô∏è JE≈öLI BRAK FAKT√ìW:

```bash
# Wgraj z backup:
python3 << 'EOF'
import sqlite3, json, hashlib, time
with open('facts_complete.json') as f:
    facts = json.load(f)
conn = sqlite3.connect('data/monolit.db')
cur = conn.cursor()
cur.execute('CREATE TABLE IF NOT EXISTS ltm (id TEXT PRIMARY KEY, text TEXT, tags TEXT, source TEXT, conf REAL, created_at INTEGER)')
for fact in facts:
    fid = hashlib.sha256(fact['text'].encode()).hexdigest()[:16]
    tags = ','.join(fact['tags']) if isinstance(fact['tags'], list) else fact['tags']
    cur.execute('INSERT OR IGNORE INTO ltm VALUES (?,?,?,?,?,?)', 
                (fid, fact['text'], tags, fact.get('source',''), fact.get('conf',0.75), int(time.time())))
conn.commit()
print(f'‚úÖ {len(facts)} fakt√≥w')
EOF
```

---

**GOTOWE! Teraz wiesz jak dzia≈Ça wiedza w systemie! üß†**
